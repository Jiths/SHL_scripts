{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sparse Hebbian Learning : reproducing SparseNet\n",
    "\n",
    "In this notebook, we test the convergence of SparseNet as a function of different learning parameters. This shows the relative robusteness of this method according to the coding parameters, but also the importance of homeostasis to obtain an efficient set of filters.\n",
    "\n",
    "See also :\n",
    "* http://blog.invibe.net/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html for a description of how SparseNet is implemented in the scikit-learn package\n",
    "* http://blog.invibe.net/posts/2015-05-06-reproducing-olshausens-classical-sparsenet-part-2.html for a descrtiption of how we managed to implement the homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "\n",
    "list_figures = ['show_dico', 'plot_variance',  'plot_variance_histogram',  'time_plot_prob',  'time_plot_kurt',  'time_plot_var']\n",
    "DEBUG_DOWNSCALE, verbose = 10, 0\n",
    "DEBUG_DOWNSCALE, verbose = 10, 100\n",
    "DEBUG_DOWNSCALE, verbose = 1, 0\n",
    "N_scan = 9\n",
    "\n",
    "shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, verbose=verbose)\n",
    "data = shl.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (204800,256) and (144,196) not aligned: 256 (dim 1) != 144 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b705e287f0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, \n\u001b[1;32m      4\u001b[0m               learning_algorithm='mp', eta=eta, verbose=verbose)\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_dico\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_figures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/laurentperrinet/pool/science/BICV/SHL_scripts/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, data, name_database, matname, folder_exp, list_figures, fname, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mdico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdico\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdico_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdico\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laurentperrinet/pool/science/BICV/SHL_scripts/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mcode\u001b[0;34m(self, data, dico, coding_algorithm, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         self.coding = sparse_encode(data, dico.dictionary,\n\u001b[1;32m    149\u001b[0m                                                 \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_algorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml0_sparseness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml0_sparseness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                                                fit_tol=None, P_cum=None, verbose=0)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laurentperrinet/pool/science/BICV/SHL_scripts/shl_scripts/shl_encode.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, algorithm, fit_tol, P_cum, l0_sparseness, verbose)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msparse_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml0_sparseness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml0_sparseness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_cum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_cum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;31m#elif algorithm == 'mp':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m#    sparse_code = mp(X, dictionary, l0_sparseness=l0_sparseness, fit=fit_tol, P_cum=None, verbose=verbose)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/laurentperrinet/pool/science/BICV/SHL_scripts/shl_scripts/shl_encode.py\u001b[0m in \u001b[0;36mmp\u001b[0;34m(X, dictionary, l0_sparseness, fit_tol, P_cum, verbose)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0mXcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# TODO: vectorize?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (204800,256) and (144,196) not aligned: 256 (dim 1) != 144 (dim 0)"
     ]
    }
   ],
   "source": [
    "for eta in np.logspace(-1, 1, N_scan, base=10)*shl.eta:\n",
    "    matname = 'homeo - eta={}'.format(eta)\n",
    "    shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, \n",
    "              learning_algorithm='mp', eta=eta, verbose=verbose)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for eta_homeo in np.logspace(-1, 1, N_scan, base=10)*shl.eta_homeo:\n",
    "    matname = 'homeo - eta_homeo={eta_homeo}'.format(eta_homeo=eta_homeo)\n",
    "    shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, \n",
    "              learning_algorithm='mp', eta_homeo=eta_homeo, verbose=verbose)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for l0_sparseness in np.logspace(3, 5, N_scan, base=2):\n",
    "    matname = 'homeo - l0_sparseness={l0_sparseness}'.format(l0_sparseness=l0_sparseness)\n",
    "    shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, \n",
    "              l0_sparseness=l0_sparseness, verbose=verbose)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without homeostasis\n",
    "\n",
    "Here,we only ensure the norm ofthe filters is constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shl = SHL()\n",
    "for eta in np.logspace(-1, 1, N_scan, base=10)*shl.eta:\n",
    "    matname = 'no homeo - eta={}'.format(eta)\n",
    "    shl = SHL(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, eta_homeo=0,\n",
    "              eta=eta, verbose=verbose)\n",
    "    dico = shl.learn_dico(data=data, matname=matname)\n",
    "    fig, ax = dico.show_dico(title=matname)\n",
    "    fig.show()\n",
    "    fig, ax = dico.plot_variance(data)\n",
    "    fig.show()\n",
    "    fig, ax = dico.plot_variance_histogram(data)\n",
    "    fig.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import version_information\n",
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
